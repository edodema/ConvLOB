{"cells":[{"cell_type":"markdown","metadata":{"id":"OJDVJSHcOWuW"},"source":["# Dependencies"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install pytorch_lightning neptune-client -qqq"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":538,"status":"ok","timestamp":1644599227623,"user":{"displayName":"Lorenzo De Matteis","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10815101602605956441"},"user_tz":-60},"id":"6PxwTBVDOehc"},"outputs":[],"source":["from typing import *\n","import requests\n","import zipfile\n","from pathlib import Path\n","\n","import numpy as np\n","from numpy.lib.stride_tricks import sliding_window_view\n","\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","import pytorch_lightning as pl\n","from pytorch_lightning.loggers import NeptuneLogger\n","import torchmetrics"]},{"cell_type":"markdown","metadata":{"id":"5cJDPcXiOM5R"},"source":["# Dataset\n","**Add info on the dataset and how we change it**"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["class LOBDataset(Dataset):\n","    def __init__(\n","        self,\n","        data: np.ndarray,\n","        input_idx: int = 40,\n","        label_idx: int = -5,\n","        window: int = 100,\n","        pred_horizon_idx: int = -1,\n","    ):\n","        \"\"\"Dataset object for FI-2010 dataset.\n","\n","        Args:\n","            data (np.ndarray): Input data array.\n","            input_idx (int, optional): Last column for input data. Defaults to 40.\n","            label_idx (int, optional): First column for labels. Defaults to -5.\n","            window (int, optional): Window size. Defaults to 100.\n","            pred_horizon_idx (int, optional): Prediction horizon index. Defaults to -1.\n","        \"\"\"\n","        super(LOBDataset, self).__init__()\n","        x, y = self._init_data(\n","            data=data,\n","            in_idx=input_idx,\n","            gt_idx=label_idx,\n","            win=window,\n","            ph_idx=pred_horizon_idx,\n","        )\n","\n","        self.x = torch.from_numpy(x.copy())\n","        self.y = torch.from_numpy(y)\n","\n","    def _init_data(\n","        self, data: np.ndarray, in_idx: int, gt_idx: int, win: int, ph_idx: int\n","    ) -> Tuple[torch.Tensor, torch.Tensor]:\n","        \"\"\"Preprocess data.\n","\n","        Args:\n","            data (np.ndarray): Input data.\n","            in_idx (int): Last column of input data we aim to consider.\n","            gt_idx (int): First column of ground truth we aim to consider.\n","            win (int): Window size.\n","            ph_idx (int): Prediction horizon index.\n","\n","        Returns:\n","            Tuple[torch.Tensor, torch.Tensor]: Preprocessed input and ground truth data.\n","        \"\"\"\n","        # Input data are the first `in_idx`` (40 by default) columns i.e. the first 10 levels\n","        # due to each level being defined by a 4-tuple (price_bid, volume_bid, price_ask, volume_ask).\n","        x = data[:, :in_idx]\n","\n","        # Labels are the last `gt_idx`` (5 by default) columns of the LOB. Possible values are:\n","        # - 1: Positive percentage change.\n","        # - 2: Stationary behavior.\n","        # - 3: Negative percentage change.\n","        # We also want them to start from 0.\n","        y = data[:, -gt_idx:] - 1\n","\n","        # Each of the `gt_idx` columns represents a different projection horizon, for simplicity we keep one only.\n","        y = y[:, ph_idx]\n","\n","        # We split the input data in windows of length `win`, then trim the first `win` elements of the labels.\n","        x_win, y_trim = self._slide_window(x=x, y=y, win=win)\n","\n","        return x_win, y_trim\n","\n","    def _slide_window(\n","        self, x: np.ndarray, y: np.ndarray, win: int\n","    ) -> Tuple[torch.Tensor, torch.Tensor]:\n","        \"\"\"Split data in windows.\n","\n","        Args:\n","            x (np.ndarray): Input data.\n","            y (np.ndarray): Ground truth.\n","            win (int): Window size.\n","\n","        Returns:\n","            Tuple[torch.Tensor, torch.Tensor]: Obtained windows with their ground truth.\n","        \"\"\"\n","        x_win = sliding_window_view(x=x, window_shape=win, axis=0).transpose(0, 2, 1)\n","        y_trim = y[win - 1 :]\n","        return x_win, y_trim\n","\n","    def __len__(self) -> int:\n","        \"\"\"Data length.\n","\n","        Returns:\n","            int: Length.\n","        \"\"\"\n","        return self.x.shape[0]\n","\n","    def __getitem__(self, item: int) -> List[torch.Tensor]:\n","        \"\"\"Get item by index.\n","\n","        Args:\n","            item (int): Index.\n","\n","        Returns:\n","            List[torch.Tensor]: List with input data and label corresponding to the specified index.\n","        \"\"\"\n","        return [self.x[item], self.y[item]]"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["class LOBDataModule(pl.LightningDataModule):\n","    def __init__(\n","        self,\n","        data_dir: Path,\n","        batch_size: int,\n","        input_idx: int = 40,\n","        label_idx: int = -5,\n","        window: int = 100,\n","        pred_horizon_idx: int = -1,\n","    ):\n","        self.data_dir = data_dir\n","        self.batch_size = batch_size\n","\n","        self.input_idx = input_idx\n","        self.label_idx = label_idx\n","        self.window = window\n","        self.pred_horizon_idx = pred_horizon_idx\n","\n","    def prepare_data(self):\n","        \"\"\"Prepare data.\"\"\"\n","        data_file = self.data_dir / \"data.zip\"\n","\n","        # * Download data.zip if necessary.\n","        if not data_file.exists():\n","            url = \"https://raw.githubusercontent.com/zcakhaa/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books/master/data/data.zip\"\n","\n","            # Download.\n","            print(f\"Downloading data from {url}...\")\n","            r = requests.get(url)\n","            open(data_file, \"wb\").write(r.content)\n","\n","            # Extract.\n","            print(f\"Inflating {data_file}...\")\n","            with zipfile.ZipFile(data_file, \"r\") as zip_ref:\n","                zip_ref.extractall(self.data_dir)\n","\n","        # # * Data preprocessing.\n","        train_path = self.data_dir / \"train.gz\"\n","        val_path = self.data_dir / \"val.gz\"\n","        test_path = self.data_dir / \"test.gz\"\n","\n","        # If data is not preprocessed, do it.\n","        if not all(f.exists() for f in [train_path, val_path, test_path]):\n","            self._prepare_data()\n","            print()\n","\n","    def _prepare_data(self):\n","        \"\"\"Load and split data according to a 80-20 rate, then save the new splits.\n","\n","        Args:\n","            path (Path): Path of the FI-2010 `data.zip` file.\n","        \"\"\"\n","\n","        train_file = \"Train_Dst_NoAuction_DecPre_CF_7.txt\"\n","        test_files = [\n","            \"Test_Dst_NoAuction_DecPre_CF_7.txt\",\n","            \"Test_Dst_NoAuction_DecPre_CF_8.txt\",\n","            \"Test_Dst_NoAuction_DecPre_CF_9.txt\",\n","        ]\n","\n","        # * Prepare data.\n","        # Load as NumPy arrays.\n","\n","        print(f\"Loading {train_file}...\")\n","        train_val = np.loadtxt(self.data_dir / train_file)\n","\n","        # Split into train and val according to a 80-20 ratio.\n","        train = train_val[:, : int(np.floor(train_val.shape[1] * 0.8))]\n","        val = train_val[:, int(np.floor(train_val.shape[1] * 0.8)) :]\n","\n","        test = []\n","        for f in test_files:\n","            print(f\"Loading {train_file}...\")\n","            test.append(np.loadtxt(self.data_dir / f))\n","\n","        test = np.hstack(test)\n","\n","        # * Save data.\n","        print(f\"Saving {self.data_dir / 'train.gz'}...\")\n","        np.savetxt(self.data_dir / \"train.gz\", train.T)\n","\n","        print(f\"Saving {self.data_dir / 'val.gz'}...\")\n","        np.savetxt(self.data_dir / \"val.gz\", val.T)\n","\n","        print(f\"Saving {self.data_dir / 'test.gz'}...\")\n","        np.savetxt(self.data_dir / \"test.gz\", test.T)\n","\n","    def setup(self, stage: Optional[str] = None):\n","        \"\"\"Setup datasets.\n","\n","        Args:\n","            stage (Optional[str], optional): Stage in which we are e.g. \"fit\", \"test\". Defaults to None.\n","        \"\"\"\n","        # Assign train/val splits.\n","        if stage in (None, \"fit\"):\n","            train_file = self.data_dir / \"train.gz\"\n","            print(f\"Loading {train_file}...\")\n","            self.train = LOBDataset(\n","                data=np.loadtxt(train_file),\n","                input_idx=self.input_idx,\n","                label_idx=self.label_idx,\n","                window=self.window,\n","                pred_horizon_idx=self.pred_horizon_idx,\n","            )\n","\n","            val_file = self.data_dir / \"val.gz\"\n","            print(f\"Loading {val_file}...\")\n","            self.val = LOBDataset(\n","                data=np.loadtxt(val_file),\n","                input_idx=self.input_idx,\n","                label_idx=self.label_idx,\n","                window=self.window,\n","                pred_horizon_idx=self.pred_horizon_idx,\n","            )\n","        # Assign test split.\n","        if stage in (None, \"test\"):\n","            test_file = self.data_dir / \"test.gz\"\n","            print(f\"Loading {test_file}...\")\n","            self.test = LOBDataset(\n","                data=np.loadtxt(test_file),\n","                input_idx=self.input_idx,\n","                label_idx=self.label_idx,\n","                window=self.window,\n","                pred_horizon_idx=self.pred_horizon_idx,\n","            )\n","\n","    def train_dataloader(self) -> DataLoader:\n","        \"\"\"Get train dataloader.\n","\n","        Returns:\n","            DataLoader: Train dataloader.\n","        \"\"\"\n","        return DataLoader(\n","            self.train,\n","            batch_size=self.batch_size,\n","            shuffle=True,\n","            num_workers=12,\n","            pin_memory=True,\n","        )\n","\n","    def val_dataloader(self) -> DataLoader:\n","        \"\"\"Get val dataloader.\n","\n","        Returns:\n","            DataLoader: Val dataloader.\n","        \"\"\"\n","        return DataLoader(\n","            self.val,\n","            batch_size=self.batch_size,\n","            shuffle=False,\n","            num_workers=12,\n","            pin_memory=True,\n","        )\n","\n","    def test_dataloader(self) -> DataLoader:\n","        \"\"\"Get test dataloader.\n","\n","        Returns:\n","            DataLoader: Test dataloader.\n","        \"\"\"\n","        return DataLoader(\n","            self.test,\n","            batch_size=self.batch_size,\n","            shuffle=True,\n","            num_workers=12,\n","            pin_memory=True,\n","        )"]},{"cell_type":"markdown","metadata":{},"source":["## Model\n","\n","**Add something on the model**"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["class Flatten(nn.Module):\n","    def __init__(self):\n","        \"\"\"Flatten module.\"\"\"\n","        super(Flatten, self).__init__()\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        \"\"\"Forward pass.\n","\n","        Args:\n","            x (torch.Tensor): Input tensor.\n","\n","        Returns:\n","            torch.Tensor: Output tensor.\n","        \"\"\"\n","        batch_size = x.shape[0]\n","        return x.view(batch_size, -1)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["class Squeeze(nn.Module):\n","    def __init__(self, dim: int = -1):\n","        \"\"\"Squeeze module.\n","\n","        Args:\n","            dim (int, optional): Dimension on which we squeeze. Defaults to -1.\n","        \"\"\"\n","        super(Squeeze, self).__init__()\n","        self.dim = dim\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        \"\"\"Forward pass.\n","\n","        Args:\n","            x (torch.Tensor): Input tensor.\n","\n","        Returns:\n","            torch.Tensor: Output tensor.\n","        \"\"\"\n","        return x.squeeze(dim=self.dim)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["class Unsqueeze(nn.Module):\n","    def __init__(self, dim: int = -1):\n","        \"\"\"Unsqueeze module.\n","\n","        Args:\n","            dim (int, optional): Dimension on which we unsqueeze. Defaults to -1.\n","        \"\"\"\n","        super(Unsqueeze, self).__init__()\n","        self.dim = dim\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        \"\"\"Forward pass.\n","\n","        Args:\n","            x (torch.Tensor): Input tensor.\n","\n","        Returns:\n","            torch.Tensor: Output tensor.\n","        \"\"\"\n","        return x.unsqueeze(dim=self.dim)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self, num_classes: int = 3):\n","        \"\"\"Neural network.\n","\n","        Args:\n","            num_classes (int, optional): Number of classes. Defaults to 3.\n","        \"\"\"\n","        super(Model, self).__init__()\n","\n","        self.net = nn.Sequential(\n","            Unsqueeze(dim=1),\n","            #\n","            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=4),\n","            nn.LeakyReLU(negative_slope=0.2),\n","            #\n","            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=4),\n","            nn.MaxPool2d(kernel_size=2),\n","            nn.LeakyReLU(negative_slope=0.2),\n","            #\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),\n","            nn.LeakyReLU(negative_slope=0.2),\n","            #\n","            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3),\n","            nn.MaxPool2d(kernel_size=2),\n","            nn.LeakyReLU(negative_slope=0.2),\n","            #\n","            nn.Flatten(),\n","            #\n","            nn.Linear(in_features=4032, out_features=32),\n","            nn.Linear(in_features=32, out_features=num_classes),\n","        )\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        \"\"\"Forward pass.\n","\n","        Args:\n","            x (torch.Tensor): Input tensor.\n","\n","        Returns:\n","            torch.Tensor: Output logits.\n","        \"\"\"\n","        return self.net(x)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["class LitModel(pl.LightningModule):\n","    def __init__(\n","        self,\n","        lr: float,\n","        decay: bool = False,\n","        num_classes: int = 3,\n","    ):\n","        \"\"\"Neural network Lightning module.\n","\n","        Args:\n","            num_classes (int, optional): Number of classes. Defaults to 3.\n","        \"\"\"\n","        super(LitModel, self).__init__()\n","        self.save_hyperparameters()\n","\n","        self.model = Model()\n","        self.criterion = nn.CrossEntropyLoss()\n","\n","        # * Metrics.\n","        self.train_recall = torchmetrics.Recall()\n","        self.val_recall = torchmetrics.Recall()\n","        self.test_recall = torchmetrics.Recall()\n","\n","        self.train_precision = torchmetrics.Precision()\n","        self.val_precision = torchmetrics.Precision()\n","        self.test_precision = torchmetrics.Precision()\n","\n","        self.train_f1 = torchmetrics.F1Score()\n","        self.val_f1 = torchmetrics.F1Score()\n","        self.test_f1 = torchmetrics.F1Score()\n","\n","        self.train_cohen = torchmetrics.CohenKappa(num_classes=num_classes)\n","        self.val_cohen = torchmetrics.CohenKappa(num_classes=num_classes)\n","        self.test_cohen = torchmetrics.CohenKappa(num_classes=num_classes)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        \"\"\"Forward pass.\n","\n","        Args:\n","            x (torch.Tensor): Input tensor.\n","\n","        Returns:\n","            torch.Tensor: Output logits.\n","        \"\"\"\n","        return self.model(x)\n","\n","    def step(self, batch: List[torch.Tensor]) -> List[torch.Tensor]:\n","        \"\"\"Base step.\n","\n","        Args:\n","            batch (List[torch.Tensor]): Input batch.\n","\n","        Returns:\n","            List[torch.Tensor]: Loss and predictions' indices.\n","        \"\"\"\n","        x, y = batch\n","        x = x.to(torch.float)\n","        y = y.to(torch.long)\n","\n","        logits = self(x)\n","\n","        preds = torch.argmax(logits, dim=1)\n","        loss = self.criterion(logits, y)\n","\n","        return [loss, preds]\n","\n","    def training_step(\n","        self, batch: List[torch.Tensor], batch_idx: Optional[int]\n","    ) -> torch.Tensor:\n","        \"\"\"Base trining step.\n","\n","        Args:\n","            batch (List[torch.Tensor]): Input batch.\n","            batch_idx (Optional[int]): Input batch's index.\n","\n","        Returns:\n","            [torch.Tensor]: Loss.\n","        \"\"\"\n","        y = batch[1].to(torch.long)\n","        loss, preds = self.step(batch)\n","\n","        self.train_recall(preds, y)\n","        self.train_precision(preds, y)\n","        self.train_f1(preds, y)\n","        self.train_cohen(preds, y)\n","\n","        self.log_dict(\n","            {\n","                \"train/loss\": loss,\n","                \"train/recall\": self.train_recall.compute(),\n","                \"train/precision\": self.train_precision.compute(),\n","                \"train/f1\": self.train_f1.compute(),\n","                \"train/cohen\": self.train_cohen.compute(),\n","            },\n","            prog_bar=True,\n","            on_step=True,\n","            on_epoch=True,\n","        )\n","\n","        return loss\n","\n","    def validation_step(self, batch: List[torch.Tensor], batch_idx: Optional[int]):\n","        \"\"\"Base validation step.\n","\n","        Args:\n","            batch (List[torch.Tensor]): Input batch.\n","            batch_idx (Optional[int]): Input batch's index.\n","        \"\"\"\n","        y = batch[1].to(torch.long)\n","        loss, preds = self.step(batch)\n","\n","        self.val_recall(preds, y)\n","        self.val_precision(preds, y)\n","        self.val_f1(preds, y)\n","        self.val_cohen(preds, y)\n","\n","        self.log_dict(\n","            {\n","                \"val/loss\": loss,\n","                \"val/recall\": self.val_recall.compute(),\n","                \"val/precision\": self.val_precision.compute(),\n","                \"val/f1\": self.val_f1.compute(),\n","                \"val/cohen\": self.val_cohen.compute(),\n","            },\n","            prog_bar=True,\n","            on_step=True,\n","            on_epoch=True,\n","        )\n","\n","    def test_step(self, batch: List[torch.Tensor], batch_idx: Optional[int]):\n","        \"\"\"Base test step.\n","\n","        Args:\n","            batch (List[torch.Tensor]): Input batch.\n","            batch_idx (Optional[int]): Input batch's index.\n","        \"\"\"\n","        y = batch[1].to(torch.long)\n","        loss, preds = self.step(batch)\n","\n","        self.test_recall(preds, y)\n","        self.test_precision(preds, y)\n","        self.test_f1(preds, y)\n","        self.test_cohen(preds, y)\n","\n","        self.log_dict(\n","            {\n","                \"test/loss\": loss,\n","                \"test/recall\": self.test_recall.compute(),\n","                \"test/precision\": self.test_precision.compute(),\n","                \"test/f1\": self.test_f1.compute(),\n","                \"test/cohen\": self.test_cohen.compute(),\n","            },\n","            prog_bar=True,\n","            on_step=True,\n","            on_epoch=True,\n","        )\n","\n","    def configure_optimizers(self) -> List[torch.optim.Optimizer]:\n","        \"\"\"Configure optimizer.\n","\n","        Returns:\n","            List[torch.optim.Optimizer]: List of optimizers.\n","        \"\"\"\n","        opt = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n","\n","        if not self.hparams.decay:\n","            return [opt]\n","        else:\n","            scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(opt)\n","            return [opt, scheduler]\n"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Global seed set to 42\n","GPU available: False, used: False\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n"]},{"name":"stdout","output_type":"stream","text":["Loading data/train.gz...\n","Loading data/val.gz...\n","https://app.neptune.ai/edodema/LimitOrderBook/e/LOB-3\n"]},{"name":"stderr","output_type":"stream","text":["Info (NVML): NVML Shared Library Not Found. GPU usage metrics may not be reported. For more information, see https://docs.neptune.ai/you-should-know/what-can-you-log-and-display#hardware-consumption\n"]},{"name":"stdout","output_type":"stream","text":["Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"]},{"name":"stderr","output_type":"stream","text":["\n","   | Name            | Type             | Params\n","------------------------------------------------------\n","0  | model           | Model            | 147 K \n","1  | criterion       | CrossEntropyLoss | 0     \n","2  | train_recall    | Recall           | 0     \n","3  | val_recall      | Recall           | 0     \n","4  | test_recall     | Recall           | 0     \n","5  | train_precision | Precision        | 0     \n","6  | val_precision   | Precision        | 0     \n","7  | test_precision  | Precision        | 0     \n","8  | train_f1        | F1Score          | 0     \n","9  | val_f1          | F1Score          | 0     \n","10 | test_f1         | F1Score          | 0     \n","11 | train_cohen     | CohenKappa       | 0     \n","12 | val_cohen       | CohenKappa       | 0     \n","13 | test_cohen      | CohenKappa       | 0     \n","------------------------------------------------------\n","147 K     Trainable params\n","0         Non-trainable params\n","147 K     Total params\n","0.590     Total estimated model params size (MB)\n"]},{"name":"stdout","output_type":"stream","text":["                                                                      "]},{"name":"stderr","output_type":"stream","text":["Global seed set to 42\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 0: 100%|██████████| 15911/15911 [06:00<00:00, 44.18it/s, loss=0.871, v_num=OB-3, train/loss_step=0.729, train/recall_step=0.434, train/precision_step=0.434, train/f1_step=0.434, train/cohen_step=0.0587, val/loss_step=0.756, val/recall_step=0.467, val/precision_step=0.467, val/f1_step=0.467, val/cohen_step=0.179, val/loss_epoch=0.994, val/recall_epoch=0.467, val/precision_epoch=0.467, val/f1_epoch=0.467, val/cohen_epoch=0.170, train/loss_epoch=0.997, train/recall_epoch=0.415, train/precision_epoch=0.415, train/f1_epoch=0.415, train/cohen_epoch=0.0131]\n"]}],"source":["pl.seed_everything(42)\n","\n","ROOT_DIR = Path(\".\")\n","\n","datamodule = LOBDataModule(data_dir=ROOT_DIR / \"data\", batch_size=16)\n","model = LitModel(lr=1e-3, decay=False)\n","\n","logger = NeptuneLogger(\n","    project=\"edodema/LimitOrderBook\",\n","    api_key=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI4MTIxYzBhMy1iNTAwLTQ0MzktOTlkNy1iMmVhNWMyZjM5MGIifQ==\",\n","    tags=[\"try\"],\n",")\n","\n","# ! Need to choose for which metrics we want to monitor.\n","\n","trainer = pl.Trainer(\n","    gpus=-1 if torch.cuda.is_available() else 0,\n","    max_epochs=1,\n","    logger=logger,\n","    val_check_interval=1.0,\n","    num_sanity_val_steps=1,\n",")\n","\n","# * Train and val.\n","trainer.fit(\n","    model=model,\n","    datamodule=datamodule,\n",")"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"LOB.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
